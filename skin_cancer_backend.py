# -*- coding: utf-8 -*-
"""skin_cancer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YmijZLzdiGg4HAiBLqDfr4NR-lo7-Dqb
"""
import sys
import subprocess
import pkg_resources 

def import_run():
    # --- 1. Python version check ---
    if sys.version_info[:2] != (3, 12):
        print(f"You are using Python {sys.version_info.major}.{sys.version_info.minor}. "
              "This script is optimized for Python 3.12.")

    # --- 2. Required packages ---
    packages = [
        # PyTorch (correct wheel for Python 3.12, CPU version)
        ("torch", "https://download.pytorch.org/whl/cpu"),
        ("torchvision", "https://download.pytorch.org/whl/cpu"),
        # Other packages
        ("datasets", None),
        ("Pillow", None),
        ("openai", None),

    ]

    def install_package(pkg, index_url=None):
        """Install a package if missing."""
        try:
            dist = pkg_resources.get_distribution(pkg)
            print(f"{pkg} already installed (v{dist.version})")
        except pkg_resources.DistributionNotFound:
            print(f"Installing {pkg}...")
            cmd = [sys.executable, "-m", "pip", "install", pkg]
            if index_url:
                cmd += ["--index-url", index_url]
            subprocess.check_call(cmd)

    # Install all required packages
    for pkg, url in packages:
        install_package(pkg, url)

    print("\nAll packages ready. Continuing...\n")

    # --- 3. Your actual code below ---
    # from datasets import load_dataset
    # from torchvision import models, transforms
    # from PIL import Image
    # import torch
    # import torch.nn as nn
    # import torch.nn.functional as F
    # import os
    # import io
    # from torch.utils.data import Dataset, DataLoader
    # from torch import optim
    # import openai
    # from notopenai import NotOpenAI

    print("Main code starts here...")
    # --- Your existing script logic ---       


import_run()

from datasets import load_dataset

from torchvision import models, transforms
from PIL import Image
import torch
import torch.nn as nn
import torch.nn.functional as F

import os

import PIL
import io
from  torch.utils.data import Dataset, DataLoader


from torch import optim

import openai
import sys 

sys.path.append(os.path.join(os.path.dirname(__file__), "notopenai"))
from notopenai import NotOpenAI


ds = load_dataset("marmal88/skin_cancer")

model = models.resnet50(weights="IMAGENET1K_V1")
model.eval()

train_ds= ds['train']
#1025 overlap w predetermined split

#self split so self split
train_ds = train_ds.shuffle()
train_ds = train_ds.select(range(1000))
split_row = int(len(train_ds)*0.8)

train_dataset = train_ds.select(range(split_row))
test_ds = train_ds.select(range(split_row, len(train_ds)))

train_ds = train_dataset
print(len(train_ds), len(test_ds))

for param in model.parameters():
    param.requires_grad = False  # freeze parameters

num_classes = 7
#convolution output is input features learnt - do not change
model.fc = nn.Linear(2048, 7)

for param in model.fc.parameters(): # unfreeze new model parameters
    param.requires_grad = True

preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225],
    ),
])


#load in class initializer
def interpret_byte_data(ind, dataset):
  image_bytes = dataset['image'][ind]['bytes']
  image_stream = io.BytesIO(image_bytes)
  return image_stream
def getImg(ind, dataset):
  return dataset['image'][ind]

label_ind = {}
def map_to_class_num(list):
  global label_ind
  mapped = []
  ind_count = 0
  for l in list:
    #check to see if label is value
    if l not in label_ind.keys():
      #make entry
      label_ind[l] = ind_count
      ind_count +=1
    mapped.append(label_ind[l])
  return mapped

print((train_ds['dx']))

class CustomDataset(Dataset):
    def __init__(self, dataset, device = 'cuda', transform=None):
        self.true_label_list = map_to_class_num(list(dataset['dx']))
        #print(self.data)
        self.data_x = []
        self.data_y = []
        self.files_names = {}
        for i in range(len(self.true_label_list)):
            self.files_names[dataset['lesion_id'][i]] = i
            image = getImg(i, dataset)
            #print(image)
            input_tensor = preprocess(image)#.to(device)  # push to GPU here
            self.data_x.append(input_tensor)
            self.data_y.append(torch.tensor(self.true_label_list[i]))
        # Hint: os.walk or os.listdir is useful.

    def __len__(self):
        # TODO: return number of samples
        return len(self.data_x)

    def __getitem__(self, idx):
        return self.data_x[idx], self.data_y[idx]

train_data = CustomDataset(train_ds)
test_data = CustomDataset(test_ds)

#check for overlap
train_names = set(train_data.files_names.keys())
test_names = set(test_data.files_names.keys())

overlap = train_names & test_names
print(f"Number of overlapping files: {len(overlap)}")

# #remove all those from both sets based on id
# for i in overlap:
#   ind = train_data.files_names[i]
#   ind2 = test_data.files_names[i]
#   del train_data.data_x[ind]
#   del train_data.data_y[ind]
#   del test_data.data_x[ind2]
#   del test_data.data_x[ind2]


def evaluate(model, loader, criterion, device):
    model.eval()
    val_loss = 0.0
    val_correct = 0
    val_total = 0

    with torch.no_grad():
        for images, labels in loader:
            images =  images#.to(device)
            labels = labels#.to(device)
            outputs = model(images)

            loss_val = criterion(outputs, labels)
            val_loss += loss_val.item() * images.size(0)

            _, predicted = torch.max(outputs, 1)
            val_correct += (predicted == labels).sum().item()
            val_total += labels.size(0)

    avg_loss = val_loss / val_total
    accuracy = val_correct / val_total
    return avg_loss, accuracy


def train_model(model, train_loader, test_loader, num_epochs=1, learning_rate=0.005, device='cuda'):
    model#.to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for images, labels in train_loader:
            images = images#.to(device)
            labels = list(labels)
            #print(labels)
            labels = torch.tensor(labels)

            labels = labels#.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

        train_loss = running_loss / total
        train_acc = correct / total

        val_loss, val_acc = evaluate(model, test_loader, criterion, device)

        print(f"Epoch {epoch+1}/{num_epochs}: "
              f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, "
              f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")

train_loader = DataLoader(train_data, batch_size=256, shuffle=True)
test_loader = DataLoader(test_data, batch_size=256, shuffle=True)

print(train_data.true_label_list)

#train_model(model, train_loader, test_loader)

path = 'entire_model.pt'
#torch.save(model,path)

torch.load(path, weights_only = False)
model.eval()

#predict one

def predict(image_path):
  global label_ind
  image = Image.open(image_path).convert("RGB")
  input_tensor = preprocess(image) # image is loaded from file, for example
  input_batch = input_tensor.unsqueeze(0) # input must be a batch

  with torch.no_grad():
    output = model(input_batch)
    probabilities = F.softmax(output[0], dim=0) #softmax over first image
  prob, label = torch.topk(probabilities, 1)
  print(prob)
  if prob<0.2:
      return "none detected"
  #get string w label
  label = label.item()
  for key, val in label_ind.items():
    if val == label:
      return key




openai.api_key = "zr2sCiR69vviuNTLeck8"

# If {result}  is not equal to no current detection then use result as cancer type detected and all respones should reference that specific cancer-type (or benign class) when responding. When response is referring to the word that with no other given subject use {result} as subject of query. Always check {result} value before responding. If there is no class value in {result} then give general advice or ask for example image for detection

def generate_gpt_response(prompt, result):

    client = NotOpenAI(api_key="zr2sCiR69vviuNTLeck8")

    chat_completion = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {
                "role": "system",
                "content": f"You are Doctor Skin, a helpful skin health assistant. The patient you are treating has {result}. Always respond in 3 sentences or fewer"

            },
            {
                "role": "user",
                "content": prompt
            }
        ]
    )

    return chat_completion.choices[0].message.content

result = "No current detection"
def chat_with_bot():
    print("Doctor Skin: Hello! Please upload a skin lesion image using 'analyze <image_path>' or type 'skip' to continue chatting. Type 'exit' to quit.")

    image_uploaded = False

    while True:
        user_input = input("You: ").strip()

        if user_input.lower() == "exit":
            print("Doctor Skin: Goodbye!")
            break

        # Handle image upload / analyze
        if not image_uploaded:
            if user_input.lower().startswith("analyze "):
                image_path = user_input[8:].strip()
                try:
                    # Predict class from image
                    result = predict(image_path).replace("_", " ")
                    print(f"Doctor Skin: You may have: {result}")
                    image_uploaded = True
                except Exception as e:
                    print(f"Doctor Skin: Error analyzing image: {e}")
            elif user_input.lower() == "skip":
                print("Doctor Skin: Okay, we can continue chatting without an image.")
                image_uploaded = True
            else:
                print("Doctor Skin: Please upload an image using 'analyze <image_path>' or type 'skip'.")
            continue

        # After image or skip, send input to GPT
        try:
            response = generate_gpt_response(user_input, result)
            print(f"Doctor Skin: {response}")
        except Exception as e:
            print(f"Doctor Skin: Error generating response: {e}")


#chat_with_bot()